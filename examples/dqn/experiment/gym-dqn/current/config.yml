agent:
  kwargs:
    act_dim: 2
    batch_size: 128
    device: cuda
    discount_rate: 0.99
    epsilon_schedule:
      kwargs:
        value: 0.1
      name: ConstantSchedule
    log_frequency: 100
    logger: {}
    loss_fn:
      kwargs: {}
      name: SmoothL1Loss
    min_replay_history: 500
    obs_dim: &id001
    - 4
    optimizer_fn:
      kwargs: {}
      name: Adam
    replay_buffer:
      kwargs:
        capacity: 1000
        gamma: 0.99
        observation_dtype: np.float64
        observation_shape: *id001
        stack_size: 1
      name: CircularReplayBuffer
    representation_net:
      kwargs:
        hidden_units:
        - 256
        - 256
      name: MLPNetwork
    reward_clip: 1
    target_net_update_schedule:
      kwargs:
        off_value: false
        on_value: true
        period: 100
      name: PeriodicSchedule
    test_epsilon: 0.001
    update_period_schedule:
      kwargs:
        off_value: false
        on_value: true
        period: 1
      name: PeriodicSchedule
  name: DebuggableDQNAgent
environment:
  kwargs:
    env_name: CartPole-v0
  name: GymEnv
loggers:
  kwargs:
    logger_list:
    - kwargs: {}
      name: ChompLogger
    - kwargs:
        name: gym-dqn
        project: Hive
        resume: allow
        start_method: thread
      name: WandbLogger
  name: CompositeLogger
max_steps_per_episode: 100
run_name: gym-dqn
save_dir: experiment
saving_schedule:
  kwargs:
    off_value: false
    on_value: true
    period: 10000
  name: PeriodicSchedule
stack_size: 1
test_episodes: 10
test_frequency: 200
train_steps: 5000
